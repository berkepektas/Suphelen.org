import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import re

# ---------------------------
# HABERDEN BÄ°LGÄ° Ã‡EK
# ---------------------------
def get_article_content(url):
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers, timeout=10)
    response.encoding = response.apparent_encoding
    soup = BeautifulSoup(response.text, "html.parser")

    title = soup.title.string.strip() if soup.title else "BaÅŸlÄ±k bulunamadÄ±"
    paragraphs = soup.find_all("p")
    article_text = " ".join(p.get_text() for p in paragraphs)
    if len(article_text) < 100:
        article_text = soup.get_text(separator=" ", strip=True)
    return title, article_text


# ---------------------------
# METÄ°NDEN DEPREM VERÄ°LERÄ°NÄ° Ã‡EK
# ---------------------------
def extract_info_from_text(text):
    magnitude = None
    location = None

    mag_match = re.search(r'(\d[\.,]\d)\s*(?:bÃ¼yÃ¼klÃ¼ÄŸÃ¼nde|ÅŸiddetinde)', text)
    if mag_match:
        magnitude = float(mag_match.group(1).replace(",", "."))

    # Yer tahmini (Ã¶rnek: BalÄ±kesir, Ä°zmir, Malatya)
    location_match = re.search(r'([A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+)\s*(?:\'de|\'da|\'ta|\'te)?\s+deprem', text)
    if location_match:
        location = location_match.group(1)

    return magnitude, location


# ---------------------------
# AFAD'DAN TÃœM DEPREMLER
# ---------------------------
def get_all_afad_earthquakes():
    AFAD_URL = "https://deprem.afad.gov.tr/last-earthquakes.html"
    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(AFAD_URL, headers=headers)
    res.encoding = "utf-8"
    soup = BeautifulSoup(res.text, "html.parser")

    table = soup.find("table")
    if not table:
        return []

    rows = table.find_all("tr")[1:]  # baÅŸlÄ±k satÄ±rÄ±nÄ± atla
    records = []

    for row in rows:
        cols = row.find_all("td")
        if len(cols) >= 7:  # 1-6-7 sÃ¼tunlarÄ± alÄ±yoruz
            tarih = cols[0].text.strip()
            try:
                buyukluk = float(cols[5].text.strip())
            except:
                buyukluk = 0.0
            sehir = cols[6].text.strip()

            records.append({
                "Tarih": tarih,
                "BÃ¼yÃ¼klÃ¼k": buyukluk,
                "Åehir": sehir
            })

    return records


# ---------------------------
# HABERÄ° AFAD VERÄ°SÄ°YLE KARÅILAÅTIR
# ---------------------------
def check_with_afad(magnitude, location):
    print("\n[1.A] AFAD TEYÄ°DÄ°")
    print(f"      -> Haberde iddia edilen bÃ¼yÃ¼klÃ¼k: {magnitude if magnitude else 'BelirtilmemiÅŸ'}")
    print(f"      -> Haberde geÃ§en yer: {location if location else 'BelirtilmemiÅŸ'}\n")

    depremler = get_all_afad_earthquakes()
    if not depremler:
        return "âš ï¸ AFAD verisi alÄ±namadÄ±."

    bulundu = False
    for d in depremler:
        yer_temiz = d["Åehir"].strip().lower()
        if magnitude and abs(d["BÃ¼yÃ¼klÃ¼k"] - magnitude) <= 0.3:
            if (not location) or (location.lower() in yer_temiz):
                bulundu = True
                return f"âœ… DOÄRU: AFAD kayÄ±tlarÄ±nda {d['Åehir']} civarÄ±nda {d['BÃ¼yÃ¼klÃ¼k']} bÃ¼yÃ¼klÃ¼ÄŸÃ¼nde deprem var."

    if not bulundu:
        return f"âŒ YALAN: {magnitude} bÃ¼yÃ¼klÃ¼ÄŸÃ¼nde bir deprem kaydÄ± bulunamadÄ±."


# ---------------------------
# ANA Ã‡ALIÅTIRMA
# ---------------------------
def verify_earthquake_news(url):
    print("URL analiz ediliyor, lÃ¼tfen bekleyin...\n")
    title, text = get_article_content(url)
    print(f"ğŸ“„ Haber BaÅŸlÄ±ÄŸÄ±: {title}\n")

    mag, loc = extract_info_from_text(text)
    result = check_with_afad(mag, loc)
    print(result)


# ---------------------------
# MAIN
# ---------------------------
if __name__ == "__main__":
    link = input("LÃ¼tfen haber linkini girin: ")
    verify_earthquake_news(link)
